"""
Feature-MLPè®­ç»ƒè„šæœ¬ - ä½¿ç”¨FlexiblePolicyDataset
åŸºäºé¢„è®­ç»ƒè§¦è§‰ç‰¹å¾çš„è¡Œä¸ºå…‹éš†è®­ç»ƒ
"""

import os
import sys
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from tqdm import tqdm
import numpy as np
from datetime import datetime
import wandb

# è·å–é¡¹ç›®æ ¹è·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
sys.path.append(project_root)

try:
    from tactile_representation.Prototype_Discovery.models.cnn_autoencoder import TactileCNNAutoencoder
except ImportError:
    print("è­¦å‘Š: æ— æ³•å¯¼å…¥ TactileCNNAutoencoder")
    TactileCNNAutoencoder = None
from policy_learn.models.feature_mlp_new import FeatureMLP, compute_feature_mlp_losses
from policy_learn.dataset_dataloader.flexible_policy_dataset import create_flexible_datasets

# è®¾ç½®ä»£ç†ï¼ˆå¦‚æœéœ€è¦ä»£ç†æ‰èƒ½è®¿é—®å¤–ç½‘ï¼‰
os.environ["HTTP_PROXY"] = "http://127.0.0.1:7890"
os.environ["HTTPS_PROXY"] = "http://127.0.0.1:7890"

# è®¾ç½®è¶…æ—¶æ—¶é—´
os.environ["WANDB_HTTP_TIMEOUT"] = "60"

def train_feature_mlp(config):
    """
    è®­ç»ƒFeature-MLPæ¨¡å‹
    
    Args:
        config: è®­ç»ƒé…ç½®å­—å…¸
        
    Returns:
        best_model_path: æœ€ä½³æ¨¡å‹æƒé‡è·¯å¾„
    """
    print("ğŸš€ å¼€å§‹Feature-MLPè®­ç»ƒ...")
    
    # ç™»å½•wandbï¼ˆå¦‚æœéœ€è¦çš„è¯ï¼‰
    try:
        wandb.login()
        print("âœ… wandbç™»å½•æˆåŠŸ")
    except Exception as e:
        print(f"âš ï¸  wandbç™»å½•è­¦å‘Š: {e}")
        print("ç»§ç»­è®­ç»ƒï¼Œä½†å¯èƒ½æ— æ³•ä¸Šä¼ åˆ°wandb")
    
    # åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„è¾“å‡ºç›®å½•
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = os.path.join(project_root, config['output']['output_dir'], f"feature_mlp_{timestamp}")
    os.makedirs(output_dir, exist_ok=True)
    
    # åˆå§‹åŒ–wandb
    run = wandb.init(
        entity=config.get('wandb', {}).get('entity', None),
        project=config.get('wandb', {}).get('project', 'feature-mlp-training'),
        name=f"feature_mlp_{timestamp}",
        config=config,
        dir=output_dir,
        tags=config.get('wandb', {}).get('tags', ['feature-mlp', 'tactile'])
    )
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ•°æ®é›†
    print("ğŸ“‚ åŠ è½½æ•°æ®é›†...")
    normalize_config = config['data'].get('normalize_config', {
        'forces': 'zscore',
        'actions': 'minmax',
        'end_states': None,
        'resultants': None
    })
    
    train_dataset, test_dataset = create_flexible_datasets(
        data_root=os.path.join(project_root, config['data']['data_root']),
        categories=config['data'].get('categories', None),
        train_ratio=config['data']['train_split'],
        random_seed=42,
        start_frame=config['data'].get('start_frame', 0),
        use_end_states=False,  # Feature-MLPä¸éœ€è¦çŠ¶æ€ä¿¡æ¯
        use_forces=True,       # éœ€è¦è§¦è§‰åŠ›æ•°æ®
        use_resultants=False,  # ä¸éœ€è¦åˆåŠ›æ•°æ®
        normalize_config=normalize_config,
        sequence_mode=False    # ä½¿ç”¨æ— æ—¶åºæ¨¡å¼
    )
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset,
        batch_size=config['data']['batch_size'],
        shuffle=True,
        num_workers=config['data'].get('num_workers', 4),
        pin_memory=True if device.type == 'cuda' else False
    )
    
    test_loader = DataLoader(
        test_dataset,
        batch_size=config['data']['batch_size'],
        shuffle=False,
        num_workers=config['data'].get('num_workers', 4),
        pin_memory=True if device.type == 'cuda' else False
    )
    
    print(f"âœ… è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬")
    print(f"âœ… æµ‹è¯•é›†: {len(test_dataset)} æ ·æœ¬")
    
    # åˆ›å»ºæ¨¡å‹
    print("ğŸ—ï¸ åˆ›å»ºæ¨¡å‹...")
    pretrained_path = os.path.join(project_root, config['model']['pretrained_encoder_path']) if config['model']['pretrained_encoder_path'] else None
    model = FeatureMLP(
        feature_dim=config['model']['feature_dim'],
        action_dim=config['model']['action_dim'],
        hidden_dims=config['model']['hidden_dims'],
        dropout_rate=config['model']['dropout_rate'],
        pretrained_encoder_path=pretrained_path
    )
    model = model.to(device)
    
    # åˆ›å»ºä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨
    optimizer = optim.Adam(
        model.parameters(),
        lr=config['training']['lr'],
        weight_decay=config['training']['weight_decay']
    )
    
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.5, patience=10
    )
    
    # è®­ç»ƒå¾ªç¯
    best_loss = float('inf')
    patience_counter = 0
    
    try:
        for epoch in range(config['training']['epochs']):
            print(f"\nğŸ”„ Epoch {epoch + 1}/{config['training']['epochs']}")
            
            # è®­ç»ƒé˜¶æ®µ
            train_loss, train_metrics = train_epoch(model, train_loader, optimizer, device, config['loss'])
            
            # è®°å½•è®­ç»ƒæŒ‡æ ‡åˆ°wandb
            run.log({
                'epoch': epoch,
                'train/loss': train_loss,
                'train/l1_error': train_metrics.get('l1_error', 0),
                'train/rmse': train_metrics.get('rmse', 0),
                'learning_rate': optimizer.param_groups[0]['lr']
            })
            
            # éªŒè¯é˜¶æ®µ
            if (epoch + 1) % config['training']['eval_every'] == 0:
                test_loss, test_metrics = evaluate(model, test_loader, device, config['loss'])
                
                print(f"ğŸ“Š éªŒè¯ç»“æœ:")
                print(f"   Loss: {test_loss:.6f}")
                print(f"   L1: {test_metrics['l1_error']:.6f}")
                print(f"   RMSE: {test_metrics['rmse']:.6f}")
                print(f"   Last prediction: {test_metrics['last_prediction']}")
                print(f"   Last target: {test_metrics['last_target']}")
                
                # è®°å½•éªŒè¯æŒ‡æ ‡åˆ°wandb
                run.log({
                    'epoch': epoch,
                    'val/loss': test_loss,
                    'val/l1_error': test_metrics['l1_error'],
                    'val/rmse': test_metrics['rmse']
                })
                
                # å­¦ä¹ ç‡è°ƒåº¦
                scheduler.step(test_loss)
                
                # ä¿å­˜æœ€ä½³æ¨¡å‹
                if test_loss < best_loss:
                    best_loss = test_loss
                    patience_counter = 0
                    best_model_path = os.path.join(output_dir, 'best_model.pt')
                    torch.save({
                        'epoch': epoch,
                        'model_state_dict': model.state_dict(),
                        'optimizer_state_dict': optimizer.state_dict(),
                        'loss': test_loss,
                        'metrics': test_metrics,
                        'config': config
                    }, best_model_path)
                    print(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹: {best_model_path}")
                    
                    # ä¿å­˜æ¨¡å‹åˆ°wandb
                    wandb.save(best_model_path)
                else:
                    patience_counter += 1
                
                # æ—©åœæ£€æŸ¥
                if patience_counter >= config['training']['patience']:
                    print(f"â° æ—©åœ: {config['training']['patience']} è½®æ— æ”¹å–„")
                    break
            
            # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
            if (epoch + 1) % config['training']['save_every'] == 0:
                checkpoint_path = os.path.join(output_dir, f'checkpoint_epoch_{epoch+1}.pt')
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'loss': train_loss,
                    'config': config
                }, checkpoint_path)
                print(f"ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: {checkpoint_path}")
        
        print(f"ğŸ‰ è®­ç»ƒå®Œæˆ! æœ€ä½³éªŒè¯æŸå¤±: {best_loss:.6f}")
        
        # è®°å½•æœ€ç»ˆç»“æœ
        run.log({'final/best_loss': best_loss})
        
        return best_model_path
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        raise
    finally:
        # ç»“æŸwandbè¿è¡Œ
        run.finish()


def train_epoch(model, train_loader, optimizer, device, loss_config):
    """è®­ç»ƒä¸€ä¸ªepoch"""
    model.train()
    total_loss = 0.0
    total_metrics = {}
    total_samples = 0
    
    for batch_idx, batch in enumerate(tqdm(train_loader, desc="Training")):
        # è·å–æ‰¹æ¬¡æ•°æ®
        forces_l = batch['forces_l'].to(device)  # (B, 3, 20, 20)
        forces_r = batch['forces_r'].to(device)  # (B, 3, 20, 20)
        actions = batch['action'].to(device)     # (B, 6) ä½†æˆ‘ä»¬åªéœ€è¦å‰3ç»´
        
        # åªä½¿ç”¨ä½ç½®å¢é‡ (dx, dy, dz)
        targets = actions[:, :3]  # (B, 3)
        
        batch_size = forces_l.size(0)
        if batch_size == 0:
            continue
        
        # å‰å‘ä¼ æ’­
        optimizer.zero_grad()
        predictions = model(forces_l, forces_r)  # (B, 3)
        
        # è®¡ç®—æŸå¤±
        loss, metrics = compute_feature_mlp_losses(predictions, targets, loss_config)
        
        # åå‘ä¼ æ’­
        loss.backward()
        
        # æ¢¯åº¦è£å‰ª
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        
        optimizer.step()
        
        # ç´¯åŠ ç»Ÿè®¡
        total_loss += loss.item() * batch_size
        total_samples += batch_size
        
        # ç´¯åŠ æŒ‡æ ‡ï¼ˆè·³è¿‡åˆ—è¡¨ç±»å‹ï¼‰
        for key, value in metrics.items():
            if isinstance(value, (int, float)):
                if key not in total_metrics:
                    total_metrics[key] = 0.0
                total_metrics[key] += value * batch_size
    
    # è®¡ç®—å¹³å‡å€¼
    avg_loss = total_loss / max(total_samples, 1)
    avg_metrics = {key: value / max(total_samples, 1) for key, value in total_metrics.items()}
    
    print(f"ğŸ”„ è®­ç»ƒ: Loss={avg_loss:.6f}, L1={avg_metrics.get('l1_error', 0):.6f}, RMSE={avg_metrics.get('rmse', 0):.6f}")
    
    return avg_loss, avg_metrics


def evaluate(model, test_loader, device, loss_config):
    """è¯„ä¼°æ¨¡å‹"""
    model.eval()
    total_loss = 0.0
    total_metrics = {}
    total_samples = 0
    
    with torch.no_grad():
        for batch in tqdm(test_loader, desc="Evaluating"):
            forces_l = batch['forces_l'].to(device)
            forces_r = batch['forces_r'].to(device)
            actions = batch['action'].to(device)
            
            targets = actions[:, :3]  # åªä½¿ç”¨ä½ç½®å¢é‡
            batch_size = forces_l.size(0)
            
            if batch_size == 0:
                continue
            
            # å‰å‘ä¼ æ’­
            predictions = model(forces_l, forces_r)
            
            # è®¡ç®—æŸå¤±
            loss, metrics = compute_feature_mlp_losses(predictions, targets, loss_config)
            
            # ç´¯åŠ ç»Ÿè®¡
            total_loss += loss.item() * batch_size
            total_samples += batch_size
            
            # ç´¯åŠ æŒ‡æ ‡ï¼ˆè·³è¿‡åˆ—è¡¨ç±»å‹ï¼‰
            for key, value in metrics.items():
                if isinstance(value, (int, float)):
                    if key not in total_metrics:
                        total_metrics[key] = 0.0
                    total_metrics[key] += value * batch_size
                elif key in ['last_prediction', 'last_target']:
                    # ä¿ç•™æœ€åä¸€ç»„é¢„æµ‹å€¼å’ŒçœŸå®å€¼
                    total_metrics[key] = value
    
    # è®¡ç®—å¹³å‡å€¼
    avg_loss = total_loss / max(total_samples, 1)
    avg_metrics = {key: value / max(total_samples, 1) if isinstance(value, (int, float)) else value 
                   for key, value in total_metrics.items()}
    
    return avg_loss, avg_metrics


def main(config):
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ Feature-MLPè®­ç»ƒå¼€å§‹")
    print(f"ğŸ“Š é…ç½®æ‘˜è¦:")
    print(f"   æ•°æ®æ ¹ç›®å½•: {config['data']['data_root']}")
    print(f"   æ‰¹æ¬¡å¤§å°: {config['data']['batch_size']}")
    print(f"   å­¦ä¹ ç‡: {config['training']['lr']}")
    print(f"   è®­ç»ƒè½®æ•°: {config['training']['epochs']}")
    print(f"   è¾“å‡ºç›®å½•: {config['output']['output_dir']}")
    
    best_model_path = train_feature_mlp(config)
    print(f"âœ… è®­ç»ƒå®Œæˆï¼Œæœ€ä½³æ¨¡å‹: {best_model_path}")
    
    return best_model_path


if __name__ == '__main__':
    # é»˜è®¤é…ç½® - ä½¿ç”¨ç›¸å¯¹è·¯å¾„
    config = {
        'data': {
            'data_root': 'datasets/data25.7_aligned',  # ç›¸å¯¹äºproject_rootçš„è·¯å¾„
            'categories': [
                "cir_lar", "cir_med", "cir_sma",
                "rect_lar", "rect_med", "rect_sma", 
                "tri_lar", "tri_med", "tri_sma"
            ],
            'train_split': 0.8,
            'batch_size': 32,
            'num_workers': 4,
            'start_frame': 0,
            'normalize_config': {
                'forces': 'zscore',    # è§¦è§‰åŠ›æ•°æ®æ ‡å‡†åŒ–
                'actions': 'minmax',   # åŠ¨ä½œæ•°æ®å½’ä¸€åŒ–åˆ°[-1,1]
                'end_states': None,    # ä¸ä½¿ç”¨çŠ¶æ€æ•°æ®
                'resultants': None     # ä¸ä½¿ç”¨åˆåŠ›æ•°æ®
            }
        },
        'model': {
            'feature_dim': 128,
            'action_dim': 3,  # è¾“å‡º (dx, dy, dz)
            'hidden_dims': [256, 128],  # 256 â†’ 128 â†’ 3
            'dropout_rate': 0.25,       # æé«˜åˆ°0.25
            'pretrained_encoder_path': 'tactile_representation/prototype_library/cnnae_crt_128.pt'  # ç›¸å¯¹è·¯å¾„
        },
        'loss': {
            'loss_type': 'huber',
            'huber_delta': 1.0
        },
        'training': {
            'epochs': 100,
            'lr': 1e-4,
            'weight_decay': 1e-4,
            'eval_every': 5,
            'save_every': 20,
            'patience': 15
        },
        'output': {
            'output_dir': 'policy_learn/checkpoints'  # ç›¸å¯¹è·¯å¾„ï¼Œå®é™…ä¼šåœ¨ä¸‹é¢åˆ›å»ºæ—¶é—´æˆ³å­æ–‡ä»¶å¤¹
        },
        'wandb': {
            'project': 'tactile-feature-mlp',
            'tags': ['feature-mlp', 'tactile', 'behavior-cloning'],
            'notes': 'Feature-MLP training with pretrained tactile encoder and flexible dataset'
        }
    }
    
    # æ£€æŸ¥è·¯å¾„
    data_path = os.path.join(project_root, config['data']['data_root'])
    pretrained_path = os.path.join(project_root, config['model']['pretrained_encoder_path'])
    
    print(f"ğŸ¯ Feature-MLPè®­ç»ƒé…ç½®:")
    print(f"   é¡¹ç›®æ ¹ç›®å½•: {project_root}")
    print(f"   æ•°æ®è·¯å¾„: {data_path}")
    print(f"   é¢„è®­ç»ƒæƒé‡: {pretrained_path}")
    print(f"   è¾“å‡ºç›®å½•: {os.path.join(project_root, config['output']['output_dir'])}")
    
    if os.path.exists(data_path):
        print(f"âœ… æ•°æ®è·¯å¾„å­˜åœ¨")
    else:
        print(f"âŒ æ•°æ®è·¯å¾„ä¸å­˜åœ¨: {data_path}")
    
    if os.path.exists(pretrained_path):
        print(f"âœ… é¢„è®­ç»ƒæƒé‡å­˜åœ¨")
    else:
        print(f"âš ï¸  é¢„è®­ç»ƒæƒé‡ä¸å­˜åœ¨: {pretrained_path}")
        print("å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–")
        config['model']['pretrained_encoder_path'] = ''
    
    # å¼€å§‹è®­ç»ƒ
    print("\n" + "="*60)
    print("å‡†å¤‡å¼€å§‹è®­ç»ƒï¼Œè¯·ç¡®ä¿:")
    print("1. å·²å®‰è£…wandb: pip install wandb")
    print("2. å·²ç™»å½•wandb: wandb login")
    print("3. æ•°æ®è·¯å¾„æ­£ç¡®")
    print("="*60)
    
    # å–æ¶ˆæ³¨é‡Šä¸‹é¢è¿™è¡Œæ¥å®é™…è¿è¡Œè®­ç»ƒ
    main(config)
