"""
Feature-MLPæ¨¡å‹ - åŸºäºé¢„è®­ç»ƒè§¦è§‰ç‰¹å¾çš„è¡Œä¸ºå…‹éš†
ä½¿ç”¨é¢„è®­ç»ƒçš„CNNè‡ªç¼–ç å™¨æå–å·¦å³æ‰‹è§¦è§‰ç‰¹å¾ï¼Œç„¶åç”¨MLPå­¦ä¹ åŠ¨ä½œæ˜ å°„
"""

import os
import sys
import torch
import torch.nn as nn
import torch.nn.functional as F

# è·å–é¡¹ç›®æ ¹è·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
sys.path.append(project_root)

try:
    from tactile_representation.Prototype_Discovery.models.cnn_autoencoder import TactileCNNAutoencoder
except ImportError:
    print("è­¦å‘Š: æ— æ³•å¯¼å…¥ TactileCNNAutoencoder")
    TactileCNNAutoencoder = None


class FeatureMLP(nn.Module):
    """
    Feature-MLPæ¨¡å‹ï¼šåŸºäºé¢„è®­ç»ƒè§¦è§‰ç‰¹å¾çš„è¡Œä¸ºå…‹éš†
    
    æ¶æ„ï¼š
    1. é¢„è®­ç»ƒCNNç¼–ç å™¨æå–å·¦å³æ‰‹è§¦è§‰ç‰¹å¾ (2 Ã— 128ç»´)
    2. ç‰¹å¾è¿æ¥åè¾“å…¥MLP (256 â†’ 256 â†’ 128 â†’ 3)
    3. è¾“å‡º3ç»´ä½ç½®å¢é‡ (dx, dy, dz)
    """
    
    def __init__(self, 
                 feature_dim=128,           # å•æ‰‹ç‰¹å¾ç»´åº¦
                 action_dim=3,              # è¾“å‡ºåŠ¨ä½œç»´åº¦ (dx, dy, dz)
                 hidden_dims=[256, 128],    # éšè—å±‚ç»´åº¦ï¼š256 â†’ 128
                 dropout_rate=0.25,         # æé«˜Dropoutåˆ°0.25
                 pretrained_encoder_path=None):
        """
        Args:
            feature_dim: å•æ‰‹è§¦è§‰ç‰¹å¾ç»´åº¦
            action_dim: è¾“å‡ºåŠ¨ä½œç»´åº¦
            hidden_dims: MLPéšè—å±‚ç»´åº¦åˆ—è¡¨
            dropout_rate: Dropoutæ¯”ç‡
            pretrained_encoder_path: é¢„è®­ç»ƒç¼–ç å™¨æƒé‡è·¯å¾„
        """
        super(FeatureMLP, self).__init__()
        
        self.feature_dim = feature_dim
        self.action_dim = action_dim
        
        # åŠ è½½é¢„è®­ç»ƒçš„è§¦è§‰ç‰¹å¾æå–å™¨
        if TactileCNNAutoencoder is not None:
            self.tactile_encoder = TactileCNNAutoencoder(
                in_channels=3, 
                latent_dim=feature_dim
            )
            
            # åŠ è½½é¢„è®­ç»ƒæƒé‡
            if pretrained_encoder_path is not None and os.path.exists(pretrained_encoder_path):
                print(f"åŠ è½½é¢„è®­ç»ƒè§¦è§‰ç¼–ç å™¨: {pretrained_encoder_path}")
                checkpoint = torch.load(pretrained_encoder_path, map_location='cpu')
                
                # æ£€æŸ¥checkpointæ ¼å¼ï¼Œæå–æ¨¡å‹çŠ¶æ€å­—å…¸
                if isinstance(checkpoint, dict):
                    if 'model_state_dict' in checkpoint:
                        # æ ‡å‡†è®­ç»ƒcheckpointæ ¼å¼
                        model_state = checkpoint['model_state_dict']
                        print("ğŸ“¦ æ£€æµ‹åˆ°è®­ç»ƒcheckpointæ ¼å¼ï¼Œæå–model_state_dict")
                    elif 'state_dict' in checkpoint:
                        # å¦ä¸€ç§å¸¸è§æ ¼å¼
                        model_state = checkpoint['state_dict']
                        print("ğŸ“¦ æ£€æµ‹åˆ°state_dictæ ¼å¼")
                    else:
                        # ç›´æ¥çš„çŠ¶æ€å­—å…¸
                        model_state = checkpoint
                        print("ğŸ“¦ æ£€æµ‹åˆ°ç›´æ¥çŠ¶æ€å­—å…¸æ ¼å¼")
                else:
                    model_state = checkpoint
                
                # åŠ è½½çŠ¶æ€å­—å…¸
                self.tactile_encoder.load_state_dict(model_state, strict=True)
                print("âœ… æˆåŠŸåŠ è½½é¢„è®­ç»ƒæƒé‡")
                
                # æ‰“å°checkpointä¿¡æ¯
                if isinstance(checkpoint, dict) and 'epoch' in checkpoint:
                    print(f"ğŸ“Š é¢„è®­ç»ƒæ¨¡å‹ä¿¡æ¯: epoch {checkpoint['epoch']}")
                    
            else:
                print("âš ï¸  é¢„è®­ç»ƒæƒé‡è·¯å¾„æ— æ•ˆï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–")
            
            # å†»ç»“ç‰¹å¾æå–å™¨å‚æ•°
            for param in self.tactile_encoder.parameters():
                param.requires_grad = False
            print("ğŸ”’ ç‰¹å¾æå–å™¨å‚æ•°å·²å†»ç»“")
        else:
            print("âŒ æ— æ³•å¯¼å…¥CNNç¼–ç å™¨ï¼Œå°†ä½¿ç”¨éšæœºç‰¹å¾")
            self.tactile_encoder = None
        
        # æ„å»ºMLPç½‘ç»œ
        # è¾“å…¥ç»´åº¦: å·¦å³æ‰‹ç‰¹å¾è¿æ¥ = feature_dim * 2
        input_dim = feature_dim * 2
        
        layers = []
        prev_dim = input_dim
        
        for hidden_dim in hidden_dims:
            layers.extend([
                nn.Linear(prev_dim, hidden_dim),
                nn.LayerNorm(hidden_dim),
                nn.ReLU(inplace=True),
                nn.Dropout(dropout_rate)
            ])
            prev_dim = hidden_dim
        
        # è¾“å‡ºå±‚
        layers.append(nn.Linear(prev_dim, action_dim))
        
        self.mlp = nn.Sequential(*layers)
        
        # åˆå§‹åŒ–æƒé‡
        self._initialize_weights()
        
        # ç»Ÿè®¡å‚æ•°
        total_params = sum(p.numel() for p in self.parameters())
        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)
        print(f"ï¿½ æ¨¡å‹å‚æ•°: æ€»è®¡ {total_params:,}, å¯è®­ç»ƒ {trainable_params:,}")
        
    def _initialize_weights(self):
        """åˆå§‹åŒ–MLPæƒé‡"""
        for module in self.mlp.modules():
            if isinstance(module, nn.Linear):
                nn.init.xavier_uniform_(module.weight)
                if module.bias is not None:
                    nn.init.constant_(module.bias, 0)
    
    def forward(self, forces_l, forces_r):
        """
        å‰å‘ä¼ æ’­
        
        Args:
            forces_l: å·¦æ‰‹è§¦è§‰åŠ›æ•°æ® (B, 3, 20, 20)
            forces_r: å³æ‰‹è§¦è§‰åŠ›æ•°æ® (B, 3, 20, 20)
            
        Returns:
            actions: é¢„æµ‹çš„åŠ¨ä½œå¢é‡ (B, 3) - [dx, dy, dz]
        """
        batch_size = forces_l.size(0)
        
        if self.tactile_encoder is not None:
            # ä½¿ç”¨é¢„è®­ç»ƒç¼–ç å™¨æå–ç‰¹å¾
            with torch.no_grad():  # ç¼–ç å™¨å·²å†»ç»“ï¼Œä¸éœ€è¦æ¢¯åº¦
                features_l = self.tactile_encoder.encoder(forces_l)  # (B, feature_dim)
                features_r = self.tactile_encoder.encoder(forces_r)  # (B, feature_dim)
        else:
            # å¦‚æœæ²¡æœ‰ç¼–ç å™¨ï¼Œä½¿ç”¨ç®€å•çš„å…¨å±€å¹³å‡æ± åŒ–ä½œä¸ºç‰¹å¾
            features_l = torch.mean(forces_l.view(batch_size, -1), dim=1, keepdim=True)
            features_r = torch.mean(forces_r.view(batch_size, -1), dim=1, keepdim=True)
            # æ‰©å±•åˆ°æŒ‡å®šçš„ç‰¹å¾ç»´åº¦
            features_l = features_l.repeat(1, self.feature_dim)
            features_r = features_r.repeat(1, self.feature_dim)
        
        # è¿æ¥å·¦å³æ‰‹ç‰¹å¾
        combined_features = torch.cat([features_l, features_r], dim=1)  # (B, feature_dim*2)
        
        # MLPé¢„æµ‹åŠ¨ä½œ
        actions = self.mlp(combined_features)  # (B, action_dim)
        
        return actions


def compute_feature_mlp_losses(predictions, targets, config=None):
    """
    è®¡ç®—Feature-MLPæŸå¤±
    
    Args:
        predictions: æ¨¡å‹é¢„æµ‹çš„åŠ¨ä½œå¢é‡ (B, 3)
        targets: çœŸå®åŠ¨ä½œå¢é‡ (B, 3)
        config: æŸå¤±é…ç½®
        
    Returns:
        total_loss: æ€»æŸå¤±
        metrics: æŸå¤±åˆ†è§£å­—å…¸
    """
    if config is None:
        config = {}
    
    # ä¸»è¦æŸå¤±ï¼šHuber Loss (å¯¹å¼‚å¸¸å€¼æ›´é²æ£’)
    loss_type = config.get('loss_type', 'huber')
    if loss_type == 'huber':
        delta = config.get('huber_delta', 1.0)
        main_loss = F.huber_loss(predictions, targets, delta=delta)
    elif loss_type == 'mse':
        main_loss = F.mse_loss(predictions, targets)
    elif loss_type == 'l1':
        main_loss = F.l1_loss(predictions, targets)
    else:
        main_loss = F.huber_loss(predictions, targets, delta=1.0)
    
    # æ€»æŸå¤±
    total_loss = main_loss
    
    # è®¡ç®—æŒ‡æ ‡
    with torch.no_grad():
        l1_error = F.l1_loss(predictions, targets)    # å¹³å‡L1è¯¯å·®
        l2_error = F.mse_loss(predictions, targets)   # å¹³å‡L2è¯¯å·®(MSE)
        
        # è·å–æœ€åä¸€ç»„é¢„æµ‹å€¼å’ŒçœŸå®å€¼ä¾›è§‚å¯Ÿ
        last_pred = predictions[-1].cpu().numpy() if len(predictions) > 0 else None
        last_target = targets[-1].cpu().numpy() if len(targets) > 0 else None
    
    metrics = {
        'main_loss': main_loss.item(),
        'total_loss': total_loss.item(),
        'l1_error': l1_error.item(),
        'l2_error': l2_error.item(),
        'rmse': torch.sqrt(l2_error).item(),
        'last_prediction': last_pred.tolist() if last_pred is not None else [],
        'last_target': last_target.tolist() if last_target is not None else [],
    }
    
    return total_loss, metrics


if __name__ == '__main__':
    # æµ‹è¯•æ¨¡å‹åˆ›å»ºå’Œå‰å‘ä¼ æ’­
    print("ğŸ§ª æµ‹è¯•Feature-MLPæ¨¡å‹...")
    
    # åˆ›å»ºæ¨¡å‹
    model = FeatureMLP(
        feature_dim=128,
        action_dim=3,
        hidden_dims=[512, 512, 512],
        dropout_rate=0.1,
        pretrained_encoder_path=None  # æµ‹è¯•æ—¶ä¸åŠ è½½é¢„è®­ç»ƒæƒé‡
    )
    model.eval()
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 4
    forces_l = torch.randn(batch_size, 3, 20, 20)
    forces_r = torch.randn(batch_size, 3, 20, 20)
    true_actions = torch.randn(batch_size, 3)
    
    print(f"è¾“å…¥å½¢çŠ¶: forces_l {forces_l.shape}, forces_r {forces_r.shape}")
    
    # å‰å‘ä¼ æ’­
    with torch.no_grad():
        predicted_actions = model(forces_l, forces_r)
    
    print(f"è¾“å‡ºå½¢çŠ¶: {predicted_actions.shape}")
    print(f"é¢„æµ‹åŠ¨ä½œ: {predicted_actions[0].numpy()}")
    
    # æµ‹è¯•æŸå¤±è®¡ç®—
    loss, metrics = compute_feature_mlp_losses(predicted_actions, true_actions)
    print(f"æµ‹è¯•æŸå¤±: {loss.item():.6f}")
    print(f"æµ‹è¯•æŒ‡æ ‡: L1={metrics['l1_error']:.6f}, RMSE={metrics['rmse']:.6f}")
    
    print("âœ… Feature-MLPæ¨¡å‹æµ‹è¯•å®Œæˆï¼")