"""
ä¸»è®­ç»ƒè„šæœ¬ - ç»Ÿä¸€ç®¡ç†æ‰€æœ‰åŸå‹è‡ªç¼–ç å™¨æ¨¡å‹è®­ç»ƒ
"""

import os
import sys
import torch
import argparse
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..")))

from training.train_prototype_cnn_ae import main as train_prototype_cnn_ae_main
from training.train_prototype_stn_ae import main as train_prototype_stn_ae_main
from training.train_cnn_autoencoder import main as train_cnn_autoencoder_main
from training.train_vqgan import main as train_vqgan_main


def get_base_config():
    """
    è·å–åŸºç¡€é…ç½®
    """
    return {
        'data': {
            'data_root': '/home/lyj/Program_python/Tactile_blind_operation/datasets/data25.7_aligned',
            'categories': [
                "cir_lar", "cir_med", "cir_sma",
                "rect_lar", "rect_med", "rect_sma",
                "tri_lar", "tri_med", "tri_sma"
            ],
            'start_frame': 0,
            'exclude_test_folders': True,
            'normalize_method' : 'quantile_zscore',
            'num_workers': 8
        },
        'model': {
            'input_shape': (3, 20, 20),
            'feature_dim': 128,
            'share_stn': True
        },
        'training': {
            'batch_size': 64,
            'epochs': 10,
            'lr': 1e-4,
            'weight_decay': 1e-4,
            'patience': 20
        },
        'loss': {
            'diversity_lambda': 0.1,
            'entropy_lambda': 5.0,
            'sparsity_lambda': 0.01,
            'gini_lambda': 0.05,
            'stn_reg_lambda': 0.05
        }
    }


def get_model_configs():
    """
    è·å–ä¸åŒæ¨¡å‹çš„é…ç½®
    """
    base_config = get_base_config()
    
    configs = {}
    
    
    # åŸå‹è‡ªç¼–ç å™¨
    configs['prototype_cnn'] = base_config.copy()
    configs['prototype_cnn']['model']['num_prototypes'] = 8
    configs['prototype_cnn']['output'] = {
        'output_dir': os.path.join("../prototype_library", 
                                 datetime.now().strftime("%Y-%m-%d_%H-%M-%S") + "_prototype_cnn")
    }
    
    # STNåŸå‹è‡ªç¼–ç å™¨
    configs['prototype_stn'] = base_config.copy()
    configs['prototype_cnn']['model']['num_prototypes'] = 8
    configs['prototype_stn']['output'] = {
        'output_dir': os.path.join("../prototype_library", 
                                 datetime.now().strftime("%Y-%m-%d_%H-%M-%S") + "_prototype_stn")
    }
    
    # CNNè‡ªç¼–ç å™¨
    configs['cnn_autoencoder'] = {
        'data': base_config['data'].copy(),
        'model': {
            'in_channels': 3,
            'latent_dim': 128
        },
        'loss': {
            'l2_lambda': 0.001
        },
        'training': {
            'batch_size': 64,
            'epochs': 50,
            'lr': 1e-4,
            'weight_decay': 1e-4
        },
        'output': {
            'output_dir': os.path.join("../prototype_library", 
                                     datetime.now().strftime("%Y-%m-%d_%H-%M-%S") + "_cnn_autoencoder")
        }
    }
    
    
    # VQGAN
    configs['vqgan'] = {
        'data': base_config['data'].copy(),
        'model': {
            'in_channels': 3,
            'latent_dim': 128,
            'embedding_dim': 256,
            'num_embeddings': 1024,
            'commitment_cost': 0.25,
            'disc_ndf': 64
        },
        'loss': {
            'perceptual_weight': 0.1,
            'vq_weight': 1.0,
            'disc_weight': 0.1,
            'discriminator_start': 30000
        },
        'training': {
            'batch_size': 32,
            'epochs': 50,
            'lr': 1e-4,
            'disc_lr': 1e-4,
            'weight_decay': 1e-5
        },
        'output': {
            'output_dir': os.path.join("../prototype_library", 
                                     datetime.now().strftime("%Y-%m-%d_%H-%M-%S") + "_vqgan")
        }
    }
    
    
    return configs


def train_model(model_type, config=None, **kwargs):
    """
    è®­ç»ƒæŒ‡å®šç±»å‹çš„æ¨¡å‹
    Args:
        model_type: æ¨¡å‹ç±»å‹ 
        config: è‡ªå®šä¹‰é…ç½®ï¼ˆå¯é€‰ï¼‰
        **kwargs: å…¶ä»–é…ç½®å‚æ•°
    """
    # è·å–é»˜è®¤é…ç½®
    configs = get_model_configs()
    
    # æ›´æ–°é…ç½®
    if config is not None:
        if model_type in configs:
            configs[model_type].update(config)
    
    # ä»kwargsæ›´æ–°é…ç½®
    for key, value in kwargs.items():
        if '.' in key:
            # å¤„ç†åµŒå¥—é”®ï¼Œå¦‚ 'training.epochs'
            section, param = key.split('.', 1)
            if model_type in configs and section in configs[model_type]:
                configs[model_type][section][param] = value
        else:
            # é¡¶çº§å‚æ•°
            if model_type in configs and key in configs[model_type]:
                configs[model_type][key] = value

    
    if model_type == 'prototype_cnn':
        print("ğŸš€ å¼€å§‹è®­ç»ƒCNNåŸå‹è‡ªç¼–ç å™¨...")
        return train_prototype_cnn_ae_main(configs['prototype_cnn'])
    
    elif model_type == 'prototype_stn':
        print("ğŸš€ å¼€å§‹è®­ç»ƒSTNåŸå‹è‡ªç¼–ç å™¨...")
        return train_prototype_stn_ae_main(configs['prototype_stn'])
    
    elif model_type == 'cnn_autoencoder':
        print("ğŸš€ å¼€å§‹è®­ç»ƒCNNè‡ªç¼–ç å™¨...")
        return train_cnn_autoencoder_main(configs['cnn_autoencoder'])
    
    elif model_type == 'vqgan':
        print("ğŸš€ å¼€å§‹è®­ç»ƒVQGAN...")
        return train_vqgan_main(configs['vqgan'])
    
    elif model_type == 'all':
        print("ğŸš€ å¼€å§‹è®­ç»ƒæ‰€æœ‰æ¨¡å‹...")
        results = {}
        
        for model_name in ['prototype_cnn', 'prototype_stn', 'cnn_autoencoder', 'vqgan']:
            print(f"\n{'='*60}")
            print(f"è®­ç»ƒæ¨¡å‹: {model_name}")
            print(f"{'='*60}")
            
            try:
                results[model_name] = train_model(model_name, configs[model_name])
                print(f"âœ… {model_name} è®­ç»ƒæˆåŠŸå®Œæˆ!")
            except Exception as e:
                print(f"âŒ {model_name} è®­ç»ƒå¤±è´¥: {str(e)}")
                results[model_name] = None
        
        return results
    
    else:
        raise ValueError(f"æœªçŸ¥çš„æ¨¡å‹ç±»å‹: {model_type}. æ”¯æŒçš„ç±»å‹: ['prototype_cnn', 'stprototype_stnn', 'cnn_autoencoder', 'vqgan', 'all']")


def main():
    """
    ä¸»å‡½æ•° - å‘½ä»¤è¡Œæ¥å£
    å‘½ä»¤è¡Œä¸­æ¥æ”¶çš„å‚æ•°å°†è¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤å€¼
    å‚æ•°ä¼˜å…ˆçº§ï¼š
        å‘½ä»¤è¡Œå‚æ•°(cmd)  >   é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤å€¼(train_main)  >   å‡½æ•°å†…éƒ¨çš„ç¡¬ç¼–ç é»˜è®¤å€¼(train)
    """
    parser = argparse.ArgumentParser(description="åŸå‹è‡ªç¼–ç å™¨è®­ç»ƒè„šæœ¬")
    
    # åŸºæœ¬å‚æ•°
    parser.add_argument('--model', type=str, default='prototype_cnn',
                       choices=['prototype_cnn', 'prototype_stn', 'cnn_autoencoder', 'vqgan', 'all'],
                       help='è¦è®­ç»ƒçš„æ¨¡å‹ç±»å‹')
    
    # æ•°æ®å‚æ•°
    parser.add_argument('--data_root', type=str, default='/home/lyj/Program_python/Tactile_blind_operation/datasets/data25.7_aligned',
                       help='æ•°æ®æ ¹ç›®å½•')
    parser.add_argument('--batch_size', type=int, default=64,
                       help='æ‰¹å¤§å°')
    parser.add_argument('--num_workers', type=int, default=8,
                       help='æ•°æ®åŠ è½½å™¨å·¥ä½œè¿›ç¨‹æ•°')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--num_prototypes', type=int, default=8,
                       help='åŸå‹æ•°é‡')
    parser.add_argument('--feature_dim', type=int, default=128,
                       help='ç‰¹å¾ç»´åº¦ï¼ˆä»…ç”¨äºfeatureæ¨¡å‹ï¼‰')
    parser.add_argument('--share_stn', action='store_true', default=True,
                       help='æ˜¯å¦å…±äº«STNï¼ˆä»…ç”¨äºSTNæ¨¡å‹ï¼‰')
    
    # æŸå¤±å‚æ•°
    parser.add_argument('--diversity_lambda', type=float, default=0.1,
                       help='å¤šæ ·æ€§æŸå¤±æƒé‡')
    parser.add_argument('--entropy_lambda', type=float, default=10.0,
                       help='ç†µæŸå¤±æƒé‡')
    parser.add_argument('--sparsity_lambda', type=float, default=0.01,
                       help='ç¨€ç–æ€§æŸå¤±æƒé‡')
    parser.add_argument('--gini_lambda', type=float, default=0.05,
                       help='GiniæŸå¤±æƒé‡')
    parser.add_argument('--stn_reg_lambda', type=float, default=0.05,
                    help='STNæ­£åˆ™åŒ–æŸå¤±æƒé‡')
    
    # CNN Autoencoderå‚æ•°
    parser.add_argument('--latent_dim', type=int, default=128,
                       help='æ½œåœ¨ç©ºé—´ç»´åº¦ï¼ˆç”¨äºCNN autoencoderå’ŒVQGANï¼‰')
    
    # VQGANå‚æ•°
    parser.add_argument('--num_embeddings', type=int, default=1024,
                       help='ç æœ¬å¤§å°ï¼ˆç”¨äºVQGANï¼‰')
    parser.add_argument('--commitment_cost', type=float, default=0.25,
                       help='æ‰¿è¯ºæŸå¤±æƒé‡ï¼ˆç”¨äºVQGANï¼‰')
    parser.add_argument('--disc_lr', type=float, default=1e-4,
                       help='åˆ¤åˆ«å™¨å­¦ä¹ ç‡ï¼ˆç”¨äºVQGANï¼‰')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--epochs', type=int, default=50,
                       help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--lr', type=float, default=1e-4,
                       help='å­¦ä¹ ç‡')
    parser.add_argument('--weight_decay', type=float, default=1e-4,
                       help='æƒé‡è¡°å‡')
    parser.add_argument('--patience', type=int, default=20,
                       help='æ—©åœè€å¿ƒå€¼')
    
    # è¾“å‡ºå‚æ•°
    parser.add_argument('--output_dir', type=str, default=None,
                       help='è¾“å‡ºç›®å½•ï¼ˆå¦‚æœä¸æŒ‡å®šï¼Œå°†è‡ªåŠ¨ç”Ÿæˆï¼‰')
    
    args = parser.parse_args()  # è§£æå‘½ä»¤è¡Œå‚æ•°ï¼Œ  Namespace å¯¹è±¡ ä½¿ç”¨ . è®¿é—®
    
    # æ„å»ºé…ç½®æ›´æ–°
    config_updates = {}
    
    # åŠ è½½å‘½ä»¤è¡Œé…ç½®è¿›é…ç½®å­—å…¸
    # æ•°æ®é…ç½®
    config_updates['data.data_root'] = args.data_root
    config_updates['training.batch_size'] = args.batch_size
    config_updates['data.num_workers'] = args.num_workers
    
    # æ¨¡å‹é…ç½®
    config_updates['model.num_prototypes'] = args.num_prototypes
    config_updates['model.feature_dim'] = args.feature_dim
    config_updates['model.share_stn'] = args.share_stn
    config_updates['model.latent_dim'] = args.latent_dim
    config_updates['model.num_embeddings'] = args.num_embeddings
    config_updates['model.commitment_cost'] = args.commitment_cost
    
    # è®­ç»ƒé…ç½®
    config_updates['training.epochs'] = args.epochs
    config_updates['training.lr'] = args.lr
    config_updates['training.disc_lr'] = args.disc_lr
    config_updates['training.weight_decay'] = args.weight_decay
    config_updates['training.patience'] = args.patience
    
    # æŸå¤±é…ç½®
    config_updates['loss.diversity_lambda'] = args.diversity_lambda
    config_updates['loss.entropy_lambda'] = args.entropy_lambda
    config_updates['loss.sparsity_lambda'] = args.sparsity_lambda
    config_updates['loss.gini_lambda'] = args.gini_lambda
    config_updates['loss.stn_reg_lambda'] = args.stn_reg_lambda
    
    # è¾“å‡ºé…ç½®
    if args.output_dir is not None:
        config_updates['output.output_dir'] = args.output_dir
    
    # å¼€å§‹è®­ç»ƒ
    print("ğŸ¯ åŸå‹è‡ªç¼–ç å™¨è®­ç»ƒç³»ç»Ÿ")
    print(f"æ¨¡å‹ç±»å‹: {args.model}")
    print(f"æ•°æ®æ ¹ç›®å½•: {args.data_root}")
    print(f"è®­ç»ƒè½®æ•°: {args.epochs}")
    print(f"æ‰¹å¤§å°: {args.batch_size}")
    print("-" * 60)
    
    try:
        result = train_model(args.model, None, **config_updates)
        if args.model == 'all':
            print("\nğŸ‰ æ‰€æœ‰æ¨¡å‹è®­ç»ƒå®Œæˆ!")
            for model_name, model_result in result.items():
                status = "âœ… æˆåŠŸ" if model_result is not None else "âŒ å¤±è´¥"
                print(f"  {model_name}: {status}")
        else:
            print(f"\nğŸ‰ {args.model} æ¨¡å‹è®­ç»ƒå®Œæˆ!")
    
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå¤±è´¥: {str(e)}")
        return 1
    
    return 0


if __name__ == '__main__':
    sys.exit(main())
