#!/usr/bin/env python3
"""
æµ‹è¯• Feature-MLP æ¨¡å‹çš„å®Œæ•´æµç¨‹
éªŒè¯æ¨¡å‹åˆ›å»ºã€æ•°æ®åŠ è½½å’Œè®­ç»ƒé€»è¾‘
"""

import sys
import os
import torch

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('/home/lyj/Program_python/Tactile_blind_operation')

from policy_learn.models.feature_mlp import FeatureMLP, compute_feature_mlp_losses
from policy_learn.dataset_dataloader.policy_dataset import create_train_test_datasets


def test_feature_mlp_model():
    """æµ‹è¯• Feature-MLP æ¨¡å‹"""
    print("=== æµ‹è¯• Feature-MLP æ¨¡å‹ ===")
    
    # é…ç½®
    config = {
        'feature_dim': 128,
        'action_dim': 3,
        'hidden_dims': [512, 512, 512],
        'dropout_rate': 0.1,
        'pretrained_encoder_path': None  # ä½¿ç”¨éšæœºåˆå§‹åŒ–
    }
    
    # åˆ›å»ºæ¨¡å‹
    model = FeatureMLP(
        feature_dim=config['feature_dim'],
        action_dim=config['action_dim'],
        hidden_dims=config['hidden_dims'],
        dropout_rate=config['dropout_rate'],
        pretrained_encoder_path=config['pretrained_encoder_path']
    )
    
    # æµ‹è¯•è¾“å…¥
    batch_size = 4
    forces_l = torch.randn(batch_size, 3, 20, 20)
    forces_r = torch.randn(batch_size, 3, 20, 20)
    target_actions = torch.randn(batch_size, 3)
    
    # å‰å‘ä¼ æ’­
    predicted_actions = model(forces_l, forces_r)
    
    print(f"æ¨¡å‹åˆ›å»ºæˆåŠŸ!")
    print(f"è¾“å…¥å½¢çŠ¶: å·¦æ‰‹={forces_l.shape}, å³æ‰‹={forces_r.shape}")
    print(f"è¾“å‡ºå½¢çŠ¶: {predicted_actions.shape}")
    
    # æµ‹è¯•æŸå¤±è®¡ç®—
    loss_config = {'loss_type': 'huber', 'huber_delta': 1.0}
    loss, metrics = compute_feature_mlp_losses(predicted_actions, target_actions, loss_config)
    
    print(f"æŸå¤±è®¡ç®—æˆåŠŸ: {loss.item():.6f}")
    print(f"æŒ‡æ ‡: {metrics}")
    
    # ç»Ÿè®¡å‚æ•°æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"æ€»å‚æ•°æ•°é‡: {total_params:,}")
    print(f"å¯è®­ç»ƒå‚æ•°æ•°é‡: {trainable_params:,}")
    print(f"å†»ç»“å‚æ•°æ•°é‡: {total_params - trainable_params:,}")


def test_data_loading():
    """æµ‹è¯•æ•°æ®åŠ è½½"""
    print("\n=== æµ‹è¯•æ•°æ®åŠ è½½ ===")
    
    data_root = "/home/lyj/Program_python/Tactile_blind_operation/datasets/data25.7_aligned"
    
    try:
        # åˆ›å»ºæ•°æ®é›†
        train_dataset, test_dataset = create_train_test_datasets(
            data_root=data_root,
            categories=["cir_lar", "cir_med"],
            train_ratio=0.8,
            random_seed=42,
            start_frame=0,
            use_end_states=False,
            use_forces=True,
            use_resultants=False
        )
        
        print(f"æ•°æ®é›†åˆ›å»ºæˆåŠŸ!")
        print(f"è®­ç»ƒé›†å¤§å°: {len(train_dataset)}")
        print(f"æµ‹è¯•é›†å¤§å°: {len(test_dataset)}")
        
        # æµ‹è¯•æ•°æ®æ ·æœ¬
        if len(train_dataset) > 0:
            sample = train_dataset[0]
            print(f"æ ·æœ¬é”®: {list(sample.keys())}")
            
            if 'forces_l' in sample and 'forces_r' in sample:
                print(f"å·¦æ‰‹è§¦è§‰æ•°æ®å½¢çŠ¶: {sample['forces_l'].shape}")
                print(f"å³æ‰‹è§¦è§‰æ•°æ®å½¢çŠ¶: {sample['forces_r'].shape}")
                print(f"åŠ¨ä½œæ•°æ®å½¢çŠ¶: {sample['action'].shape}")
                return True
            else:
                print("è­¦å‘Š: æ ·æœ¬ä¸­ç¼ºå°‘è§¦è§‰æ•°æ®")
                return False
        else:
            print("è­¦å‘Š: è®­ç»ƒé›†ä¸ºç©º")
            return False
            
    except Exception as e:
        print(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return False


def test_training_step():
    """æµ‹è¯•è®­ç»ƒæ­¥éª¤"""
    print("\n=== æµ‹è¯•è®­ç»ƒæ­¥éª¤ ===")
    
    # åˆ›å»ºæ¨¡å‹
    model = FeatureMLP(
        feature_dim=128,
        action_dim=3,
        hidden_dims=[256, 256],  # ç®€åŒ–æ¨¡å‹
        dropout_rate=0.1,
        pretrained_encoder_path=None
    )
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    
    # æ¨¡æ‹Ÿè®­ç»ƒæ•°æ®
    batch_size = 2
    seq_len = 10
    
    # æ¨¡æ‹Ÿåºåˆ—æ•°æ®
    forces_l = torch.randn(batch_size, seq_len, 3, 20, 20)
    forces_r = torch.randn(batch_size, seq_len, 3, 20, 20)
    actions = torch.randn(batch_size, seq_len, 6)
    
    # æå–ä½ç½®ä¿¡æ¯
    positions = actions[:, :, :3]  # (B, T, 3)
    
    # å‡†å¤‡è®­ç»ƒæ•°æ®
    all_forces_l = []
    all_forces_r = []
    all_deltas = []
    
    for t in range(seq_len - 1):
        curr_forces_l = forces_l[:, t]  # (B, 3, 20, 20)
        curr_forces_r = forces_r[:, t]  # (B, 3, 20, 20)
        
        curr_pos = positions[:, t]      # (B, 3)
        next_pos = positions[:, t + 1]  # (B, 3)
        delta = next_pos - curr_pos     # (B, 3)
        
        all_forces_l.append(curr_forces_l)
        all_forces_r.append(curr_forces_r)
        all_deltas.append(delta)
    
    # åˆå¹¶æ•°æ®
    forces_l_input = torch.cat(all_forces_l, dim=0)  # (B*(T-1), 3, 20, 20)
    forces_r_input = torch.cat(all_forces_r, dim=0)  # (B*(T-1), 3, 20, 20)
    delta_targets = torch.cat(all_deltas, dim=0)     # (B*(T-1), 3)
    
    # è®­ç»ƒæ­¥éª¤
    model.train()
    optimizer.zero_grad()
    
    predicted_deltas = model(forces_l_input, forces_r_input)
    
    loss_config = {'loss_type': 'huber', 'huber_delta': 1.0}
    loss, metrics = compute_feature_mlp_losses(predicted_deltas, delta_targets, loss_config)
    
    loss.backward()
    optimizer.step()
    
    print(f"è®­ç»ƒæ­¥éª¤æˆåŠŸ!")
    print(f"è¾“å…¥å½¢çŠ¶: å·¦æ‰‹={forces_l_input.shape}, å³æ‰‹={forces_r_input.shape}")
    print(f"ç›®æ ‡å½¢çŠ¶: {delta_targets.shape}")
    print(f"é¢„æµ‹å½¢çŠ¶: {predicted_deltas.shape}")
    print(f"æŸå¤±: {loss.item():.6f}")
    print(f"MAE: {metrics.get('mae', 0):.6f}")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹æµ‹è¯• Feature-MLP ç³»ç»Ÿ...")
    
    # æµ‹è¯•æ¨¡å‹
    test_feature_mlp_model()
    
    # æµ‹è¯•æ•°æ®åŠ è½½
    data_success = test_data_loading()
    
    # æµ‹è¯•è®­ç»ƒæ­¥éª¤
    test_training_step()
    
    print("\n=== æµ‹è¯•æ€»ç»“ ===")
    print("âœ… æ¨¡å‹åˆ›å»ºå’Œå‰å‘ä¼ æ’­")
    print("âœ… æŸå¤±è®¡ç®—")
    print("âœ… è®­ç»ƒæ­¥éª¤")
    if data_success:
        print("âœ… æ•°æ®åŠ è½½")
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! ç³»ç»Ÿå‡†å¤‡å°±ç»ª.")
        print("\nä½¿ç”¨æ–¹æ³•:")
        print("python train_feature_mlp.py --config configs/feature_mlp_config.json")
    else:
        print("âŒ æ•°æ®åŠ è½½å¤±è´¥")
        print("\nâš ï¸  è¯·æ£€æŸ¥æ•°æ®è·¯å¾„å’Œæ ¼å¼")


if __name__ == '__main__':
    main()
